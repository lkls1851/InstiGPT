{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5b369d79",
   "metadata": {},
   "source": [
    "## Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbd0ad72",
   "metadata": {},
   "source": [
    "InstiGPT is an intelligent college chatbot developed using the UG Rulebook of IIT Bombay as its training dataset. This research report outlines the methodology for building InstiGPT and addresses various challenges faced during its development. The report also discusses the types of user queries that InstiGPT is designed to handle and provides insights into its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1221ed3e",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6930289",
   "metadata": {},
   "source": [
    "The primary objective of InstiGPT is to create an intelligent chatbot that can assist students and prospective applicants with information related to IIT Bombay. Beyond the significant computational power required for such a project, there are various key challenges that need to be addressed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4bda0ac",
   "metadata": {},
   "source": [
    "## Outline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "409e3df6",
   "metadata": {},
   "source": [
    "For this GPT Model, we have used the Langchain. Langchain is a framework that is used for making LLM-based applications. Previously, LLM applications were based on LSTM model. However, Langchain uses Transformer model for predictions. For LLM, we have used OpenAI GPT3.5 (da vinci) model. Following are the steps followed for developing this InstiGPT model:\n",
    "1. We will use the UG Rulebook as the training dataset for this model.\n",
    "2. First step is text extraction from the PDF file (ugrulebook.pdf). For this, we use Textract library in Python.\n",
    "3. After text extraction, this text is stored in a document file.\n",
    "4. Now we use GPT2Tokeniser for converting the text stored in the document file into tokens.\n",
    "5. Tokens are the smallest units into which a text is splitted, in order to train the model.\n",
    "6. Now, these tokens are binary coded. So we decode the tokens into UTF-08 form and write into a file of .txt format.\n",
    "7. These tokens are now grouped together to form chunks. Each chunk is a Laangchain Schema Document.\n",
    "8. Now we embed these chunks into vectors and store into a vector database using OpenAI Embeddings model and FAISS.\n",
    "9. Now. when we input a query, there will be vector similarity calculation and then vector similarity search from the vector database. \n",
    "10. From that we choose the first, most similar item.\n",
    "11. This returns context for a query. For Question-Answer model, we can use Langchain Q-A chain model as our LLM model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f367d02",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7407830e",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382322c6",
   "metadata": {},
   "source": [
    "Text was extracted from the UG Rulebook PDF using the Textract library in Python. This extracted text was stored in a document file for further processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcdd5e8d",
   "metadata": {},
   "source": [
    "### Tokenisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafad159",
   "metadata": {},
   "source": [
    "GPT2Tokenizer was used to convert the stored text into tokens, which are the smallest units for training the model. These tokens were binary coded and decoded into UTF-08 format, resulting in a .txt file."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d65bc03f",
   "metadata": {},
   "source": [
    "### Chunking and Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df361735",
   "metadata": {},
   "source": [
    "The tokens were grouped into chunks, creating Laangchain Schema Documents. OpenAI Embeddings model and FAISS were used to embed these chunks into vectors, facilitating efficient similarity search."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cfef8b",
   "metadata": {},
   "source": [
    "## Problems Faced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc11d7b",
   "metadata": {},
   "source": [
    "### Vector Similarity Calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c432c1a",
   "metadata": {},
   "source": [
    "Implementing vector similarity calculations, which are essential for efficient query handling, presented challenges in terms of computational complexity and indexing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d3f62e9",
   "metadata": {},
   "source": [
    "### User Query Understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aacbdf",
   "metadata": {},
   "source": [
    "Understanding and effectively handling user queries proved to be a complex task. Natural language processing and context understanding were critical issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d09b0101",
   "metadata": {},
   "source": [
    "### User Query Handling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b2875b",
   "metadata": {},
   "source": [
    "To ensure that InstiGPT serves its purpose effectively, it should be capable of handling a wide range of user queries. These include queries related to courses, placements, admission, campus facilities, and important dates, among others. For this we requires hyperparameter tuning, like adjusting temperature, or token length and chunk overlapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66711aae",
   "metadata": {},
   "source": [
    "## User Queries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10bab308",
   "metadata": {},
   "source": [
    "Our Chatbot should be able to address several important and wide ranging questions like:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86c062a",
   "metadata": {},
   "source": [
    "1. Course Information\n",
    "2. Placements and Internships\n",
    "3. Admission Queries\n",
    "4. Campus Facilities\n",
    "5. Important dates\n",
    "6. Scholarships and Financial Aid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
